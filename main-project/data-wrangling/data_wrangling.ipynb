{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CustomerID', 'Genre', 'Age', 'Annual Income (k$)',\n",
      "       'Spending Score (1-100)'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 'Male', 19.0, 15.0, 39.0], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data=pd.read_csv('https://storage.googleapis.com/dqlab-dataset/shopping_data.csv')\n",
    "data=pd.read_csv('https://storage.googleapis.com/dqlab-dataset/shopping_data_missingvalue.csv')\n",
    "print(data.columns)\n",
    "data.values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Customer ID  Gendre age spand score Income\n",
      "0           1    Male  19          39     15\n",
      "1           2    Male  21          81     15\n",
      "2           3  Female  20           6     16\n",
      "3           4  Female  23          77     16\n",
      "4           5  Female  31          40     17\n",
      "5           6  Female  22          76     17\n",
      "6           7  Female  35           6     18\n",
      "7           8  Female  23          94     18\n",
      "8           9    Male  64           3     19\n",
      "9          10  Female  30          72     19\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[19. 15. 39.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\data-analysis-201\\main-project\\data-wrangling\\data_wrangling.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/data-analysis-201/main-project/data-wrangling/data_wrangling.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# values_scaler=preprocessing.MinMaxScaler(feature_range=(0,1))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/data-analysis-201/main-project/data-wrangling/data_wrangling.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# data=values_scaler.fit_transform(X)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/data-analysis-201/main-project/data-wrangling/data_wrangling.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/data-analysis-201/main-project/data-wrangling/data_wrangling.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m#                       'Gendre':array[:,1]})\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/data-analysis-201/main-project/data-wrangling/data_wrangling.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# print(dataset.head(15))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/data-analysis-201/main-project/data-wrangling/data_wrangling.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m nilai_scalar\u001b[39m=\u001b[39mpreprocessing\u001b[39m.\u001b[39mMinMaxScaler(feature_range\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/data-analysis-201/main-project/data-wrangling/data_wrangling.ipynb#W1sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m data\u001b[39m=\u001b[39mnilai_scalar\u001b[39m.\u001b[39;49mfit_transform(X)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/data-analysis-201/main-project/data-wrangling/data_wrangling.ipynb#W1sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m dataset\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mDataFrame({\u001b[39m'\u001b[39m\u001b[39mAge\u001b[39m\u001b[39m'\u001b[39m:data[:,\u001b[39m0\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/data-analysis-201/main-project/data-wrangling/data_wrangling.ipynb#W1sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m                       \u001b[39m'\u001b[39m\u001b[39mIncome\u001b[39m\u001b[39m'\u001b[39m:data[:,\u001b[39m1\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/data-analysis-201/main-project/data-wrangling/data_wrangling.ipynb#W1sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m                       \u001b[39m'\u001b[39m\u001b[39mSpending Score\u001b[39m\u001b[39m'\u001b[39m:data[:,\u001b[39m2\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/data-analysis-201/main-project/data-wrangling/data_wrangling.ipynb#W1sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m                       \u001b[39m'\u001b[39m\u001b[39mID COS\u001b[39m\u001b[39m'\u001b[39m:array[:,\u001b[39m0\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/data-analysis-201/main-project/data-wrangling/data_wrangling.ipynb#W1sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m                       \u001b[39m'\u001b[39m\u001b[39mGender\u001b[39m\u001b[39m'\u001b[39m:array[:,\u001b[39m1\u001b[39m]})\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:852\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    848\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    849\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    850\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    851\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 852\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    853\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    854\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    855\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:416\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 416\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y)\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:453\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    448\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMinMaxScaler does not support sparse input. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    449\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConsider using MaxAbsScaler instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    450\u001b[0m     )\n\u001b[0;32m    452\u001b[0m first_pass \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 453\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    454\u001b[0m     X,\n\u001b[0;32m    455\u001b[0m     reset\u001b[39m=\u001b[39;49mfirst_pass,\n\u001b[0;32m    456\u001b[0m     estimator\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    457\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m    458\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    459\u001b[0m )\n\u001b[0;32m    461\u001b[0m data_min \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmin(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    462\u001b[0m data_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmax(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    565\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 566\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    567\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    568\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:769\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    767\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    768\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 769\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    770\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    771\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    772\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    773\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    774\u001b[0m         )\n\u001b[0;32m    776\u001b[0m \u001b[39m# make sure we actually converted to numeric:\u001b[39;00m\n\u001b[0;32m    777\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mOUSV\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[19. 15. 39.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "data_csv=pd.read_csv('https://storage.googleapis.com/dqlab-dataset/shopping_data.csv')\n",
    "array=data_csv.values\n",
    "X=array[0,2:5]\n",
    "Y=array[0,0:1]\n",
    "\n",
    "dataset=pd.DataFrame({'Customer ID':array[:,0],\n",
    "                      'Gendre':array[:,1],\n",
    "                      'age':array[:,2],\n",
    "                      'spand score':array[:,4],\n",
    "                      'Income':array[:,3]})\n",
    "print(dataset.head(10))\n",
    "\n",
    "# values_scaler=preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "# data=values_scaler.fit_transform(X)\n",
    "\n",
    "# dataset=pd.DataFrame({'age':data[:,0],\n",
    "#                       'Income':data[:,1],\n",
    "#                       'spand score':data[:,2],\n",
    "#                       'Customer ID':array[:,0],\n",
    "#                       'Gendre':array[:,1]})\n",
    "# print(dataset.head(15))\n",
    "\n",
    "nilai_scalar = preprocessing.MinMaxScaler(feature_range = (0, 1))\n",
    "\n",
    "data = nilai_scalar.fit_transform(X)\n",
    "dataset = pd.DataFrame({'Age':data[:,0],\n",
    "                      'Income':data[:,1],\n",
    "                      'Spending Score':data[:,2],\n",
    "                      'ID COS':array[:,0],\n",
    "                      'Gender':array[:,1]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       CustomerID         Age  Annual Income (k$)  Spending Score (1-100)\n",
      "count  200.000000  200.000000          200.000000              200.000000\n",
      "mean   100.500000   38.850000           60.560000               50.200000\n",
      "std     57.879185   13.969007           26.264721               25.823522\n",
      "min      1.000000   18.000000           15.000000                1.000000\n",
      "25%     50.750000   28.750000           41.500000               34.750000\n",
      "50%    100.500000   36.000000           61.500000               50.000000\n",
      "75%    150.250000   49.000000           78.000000               73.000000\n",
      "max    200.000000   70.000000          137.000000               99.000000\n"
     ]
    }
   ],
   "source": [
    "data= pd.read_csv('https://storage.googleapis.com/dqlab-dataset/shopping_data.csv')\n",
    "\n",
    "print(data.describe(exclude=['O']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('https://storage.googleapis.com/dqlab-dataset/shopping_data.csv')\n",
    "\n",
    "print(data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer iD  Gender Age Income Spending Score\n",
      "0            1    Male  19     15             39\n",
      "1            2    Male  21     15             81\n",
      "2            3  Female  20     16              6\n",
      "3            4  Female  23     16             77\n",
      "4            5  Female  31     17             40\n",
      "5            6  Female  22     17             76\n",
      "6            7  Female  35     18              6\n",
      "7            8  Female  23     18             94\n",
      "8            9    Male  64     19              3\n",
      "9           10  Female  30     19             72\n",
      "10          11    Male  67     19             14\n",
      "11          12  Female  35     19             99\n"
     ]
    }
   ],
   "source": [
    "data_csv=pd.read_csv('https://storage.googleapis.com/dqlab-dataset/shopping_data.csv')\n",
    "array=data_csv.values\n",
    "X=array[:,2:5]\n",
    "Y=array[:,0:1]\n",
    "\n",
    "dataset=pd.DataFrame({'Customer iD':array[:,0],\n",
    "                      'Gender':array[:,1],\n",
    "                      'Age':array[:,2],\n",
    "                      'Income':array[:,3],\n",
    "                      'Spending Score':array[:,4]})\n",
    "print(dataset.head(12))\n",
    "\n",
    "nilai_scalar=preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "data=nilai_scalar.fit_transform(X)\n",
    "\n",
    "dataset=pd.DataFrame({'Age':data[:,0],\n",
    "                      'Income':data[:,1],\n",
    "                      'Spending Score':data[:,2],\n",
    "                      'ID COS':array[:,0],\n",
    "                      'Gender':array[:,1]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "229cdfb8eedfa4964725b7eb0da8d7a63b25d97a6ab808f09bd6b506844c0629"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
